{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, List, Dict, Optional\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Date, inspect, event, types\n",
    "from sqlalchemy.orm import sessionmaker, Session, declarative_base\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "import pandas as pd\n",
    "from wifor_db import setup_logger\n",
    "\n",
    "# set up logger\n",
    "script_dir = \"log_files\"\n",
    "logger = setup_logger(\"add_regions\", script_dir)\n",
    "if logger:\n",
    "    logger.info(\"Logging setup complete\")\n",
    "else:\n",
    "    print(\"Logger setup failed.\")\n",
    "\n",
    "# Set up Base instance\n",
    "Base = declarative_base()\n",
    "\n",
    "def load_table_schema(file_path: str) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Load a table schema from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the JSON file containing the table schema.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Any]: The loaded JSON object if successful, None otherwise.\n",
    "\n",
    "    Raises:\n",
    "        logs an error message if an exception occurs during file reading or JSON loading.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading table schema: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_repr_string(name: str, columns: List[Dict[str, str]]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Create a string representation for a SQLAlchemy model class.\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of the model class.\n",
    "        columns (List[Dict[str, str]]): A list of dictionaries, each representing a column in the table.\n",
    "                                        Each dictionary should have keys like 'name' and 'type'.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: A string that can be used as the __repr__ method for a SQLAlchemy model class.\n",
    "                       Returns None if an error occurs.\n",
    "\n",
    "    Raises:\n",
    "        logs an error message if an exception occurs during string creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        repr_parts = [f\"{column['name']}='{{self.{column['name']}}}'\" if 'String' in column['type'] else f\"{column['name']}={{self.{column['name']}}}\" for column in columns]\n",
    "        standard_parts = [\"version_number={self.version_number}\", \"effective_date='{self.effective_date}'\", \"expiry_date='{self.expiry_date}'\"]\n",
    "        return f\"<{name}(\" + ', '.join(repr_parts + standard_parts) + \")>\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating representation string: {e}\")\n",
    "        return None\n",
    "\n",
    "def before_flush(cls, session: Session, flush_context: Any, instances: Any, columns: List[Dict[str, str]], unique_identifier: str) -> None:\n",
    "    \"\"\"\n",
    "    Custom 'before_flush' event handler for SQLAlchemy models.\n",
    "\n",
    "    This function is designed to be used as a class method in SQLAlchemy models. It checks for\n",
    "    duplicate entries and manages the versioning of records.\n",
    "\n",
    "    Args:\n",
    "        cls (Type[Any]): The class on which the event was invoked.\n",
    "        session (Session): The session which is flushing.\n",
    "        flush_context (Any): The context for the flush.\n",
    "        instances (Any): The set of instances participating in the flush.\n",
    "        columns (List[Dict[str, str]]): A list of dictionaries representing the columns of the table.\n",
    "        unique_identifier (str): The field name used as a unique identifier for the entries.\n",
    "\n",
    "    Raises:\n",
    "        logs an error message if an exception occurs during the flush process.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for instance in session.new:\n",
    "            if isinstance(instance, cls):\n",
    "                filter_args = {col['name']: getattr(instance, col['name']) for col in columns}\n",
    "                same_entry = session.query(cls).filter_by(**filter_args).first()\n",
    "\n",
    "                if same_entry:\n",
    "                    # If entries are identical, remove the new instance\n",
    "                    session.expunge(instance)\n",
    "                else:\n",
    "                    # Check for previous entry with the same unique identifier and no expiry date\n",
    "                    previous_entry = session.query(cls).filter_by(**{unique_identifier: getattr(instance, unique_identifier), 'expiry_date': None}).first()\n",
    "\n",
    "                    if previous_entry:\n",
    "                        # Update the existing entry expiry date\n",
    "                        new_effective_date = datetime.now() - timedelta(days=1)\n",
    "                        previous_entry.expiry_date = new_effective_date\n",
    "\n",
    "                        # Increment version number of new entry\n",
    "                        instance.version_number = previous_entry.version_number + 1\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in before_flush: {e}\")\n",
    "\n",
    "def create_engine_from_env():\n",
    "    \"\"\"\n",
    "    Creates a SQLAlchemy engine based on environment variables.\n",
    "\n",
    "    This function supports creating engines for both SQLite and MySQL databases.\n",
    "    The database type and credentials are read from environment variables.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy.engine.Engine: SQLAlchemy engine if successful, None otherwise.\n",
    "\n",
    "    Raises:\n",
    "        Logs an error message using the configured logger if an exception occurs during engine creation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        load_dotenv()\n",
    "        current_db = os.environ.get('CURRENT_DB')\n",
    "\n",
    "        if current_db == 'sqlite':\n",
    "            db_path = os.environ.get('SQLITE_DB_PATH')\n",
    "            if not db_path:\n",
    "                raise ValueError(\"SQLite database path is not set in .env file.\")\n",
    "            return create_engine(f\"sqlite:///{db_path}\", echo=False)\n",
    "\n",
    "        elif current_db == 'mysql':\n",
    "            db_user = os.environ.get('MYSQL_DB_USER')\n",
    "            db_password = os.environ.get('MYSQL_DB_PASSWORD')\n",
    "            db_host = os.environ.get('MYSQL_DB_HOST')\n",
    "            db_name = os.environ.get('MYSQL_DB_NAME')\n",
    "\n",
    "            if not all([db_user, db_password, db_host, db_name]):\n",
    "                raise ValueError(\"MySQL credentials are not set properly in .env file.\")\n",
    "\n",
    "            db_url = f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\"\n",
    "            return create_engine(db_url, echo=False)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Database type is not defined or not supported.\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        logger.error(f\"Configuration Error: {e}\")\n",
    "    except SQLAlchemyError as e:\n",
    "        logger.error(f\"SQLAlchemy Engine Creation Error: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected Error: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_session():\n",
    "    \"\"\"\n",
    "    Create and return a SQLAlchemy session.\n",
    "    \"\"\"\n",
    "    engine = create_engine_from_env()\n",
    "    try:\n",
    "        if engine is None:\n",
    "            raise ValueError(\"Engine cannot be None.\")\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        return Session()\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"SQLAlchemy Error: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Configuration Error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_table(cls):\n",
    "    \"\"\"\n",
    "    Initialize the database, create the table if it does not exist, and return a session for querying.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a session\n",
    "        session = create_session()\n",
    "        if session is None:\n",
    "            raise ValueError(\"Failed to create a session.\")\n",
    "\n",
    "        engine = session.get_bind()\n",
    "\n",
    "        # Check if the table exists and create it if not\n",
    "        if not inspect(engine).has_table(cls.__tablename__):\n",
    "            cls.metadata.create_all(engine)\n",
    "            print(f\"The table '{cls.__tablename__}' has been created in the database.\")\n",
    "\n",
    "        return session\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        print(f\"SQLAlchemy Error: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Configuration Error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "def add_data(cls, data, column_names):\n",
    "    \"\"\"\n",
    "    Add data from a pandas or geopandas DataFrame to the database table.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"Data must be a pandas or geopandas DataFrame\")\n",
    "\n",
    "    filtered_data = data[column_names]\n",
    "    session = create_session()\n",
    "\n",
    "    try:\n",
    "        for _, row in filtered_data.iterrows():\n",
    "            instance = cls(**row.to_dict())\n",
    "            session.add(instance)\n",
    "        session.commit()\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Function to create a dynamic table class based on JSON schema\n",
    "def create_class(schema):\n",
    "    name = schema['table_name']\n",
    "    columns = schema['columns']\n",
    "    unique_identifier = schema['identifier']\n",
    "\n",
    "    attrs = {'__tablename__': name}\n",
    "\n",
    "    # Add standard columns at the beginning\n",
    "    attrs['id'] = Column(Integer, primary_key=True, autoincrement=True)\n",
    "\n",
    "    # Add columns from JSON schema\n",
    "    for column in columns:\n",
    "        column_type = getattr(types, column['type'].split('(')[0])\n",
    "        if '(' in column['type']:\n",
    "            size = int(column['type'].split('(')[1].replace(')', ''))\n",
    "            column_type = column_type(size)\n",
    "        attrs[column['name']] = Column(column_type)\n",
    "\n",
    "    # Add standard columns at the end\n",
    "    attrs['version_number'] = Column(Integer, default=1)\n",
    "    attrs['effective_date'] = Column(Date, default=datetime.now)\n",
    "    attrs['expiry_date'] = Column(Date, default=None)\n",
    "\n",
    "    # Add dynamic __repr__ method\n",
    "    repr_string = create_repr_string(name, columns)\n",
    "    attrs['__repr__'] = lambda self: repr_string.format(self=self)\n",
    "\n",
    "    # Add dynamic before_flush class method\n",
    "    attrs['before_flush'] = classmethod(lambda cls, session, flush_context, instances: before_flush(cls, session, flush_context, instances, columns, unique_identifier))\n",
    "\n",
    "    # Assign functions as class methods\n",
    "    attrs['create_session'] = classmethod(lambda cls: create_session())\n",
    "    attrs['create_table'] = classmethod(create_table)\n",
    "    attrs['add_data'] = classmethod(add_data)\n",
    "\n",
    "    return type(name, (Base,), attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = load_table_schema('../wifor_db/tables/regions.json')\n",
    "Regions = create_class(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Regions.create_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "geo_df = gpd.read_file('ref-nuts-2021\\\\NUTS_RG_01M_2021_4326.geojson')\n",
    "column_names = [column['name'] for column in schema['columns']]\n",
    "\n",
    "Regions.add_data(geo_df, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Regions.create_session()\n",
    "region = session.query(Regions).filter_by(NUTS_ID=\"AT\").all()\n",
    "region"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wifor-platform-kFL7Vwem-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
